@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}
% Ignore the above

@misc{huggingface,
  title = {Hugging Face},
  author = {Wolf, Thomas and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Brew, Josh},
  year = {2019},
  howpublished = {\url{https://huggingface.co}},

}

@online{gdpr,
  title = {Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC},
  year = {2016},
  author = {{European Parliament} and {Council of the European Union}},
  url = {https://eur-lex.europa.eu/eli/reg/2016/679/oj},
  urldate = {June 16, 2023}
}


@online{pipeda,
  title = {Personal Information Protection and Electronic Documents Act (S.C. 2000, c. 5)},
  year = {2000},
  author = {{Government of Canada}},
  url = {https://laws-lois.justice.gc.ca/eng/acts/p-8.6/index.html},
  urldate = {June 16, 2023}
}


@article{Bauer2020,
author = {Bauera, Zuria             and
         Domingueza, Alejandro      and 
         Cruza, Edmanuel            and
         Gomez-Donosoa, Francisco   and
         Orts-Escolanoa, Sergio     and
         Cazorlaa, Miguel},
journal = {Pattern Recognition Letters},
volume={137},
title = {Enhancing perception for the visually impaired with deep learning techniques and low-cost wearable sensors},
pages = {27-36},
year = {2020}
}

% I think URL is not allowed in the ICLR format 
@misc{Types_of_Vision_Problems,
    author = {Agencies New York State},
    institution = {New York State Department of Health},
    title = {Types of Vision Problems},
    year = {2012}
}
% I think URL is not allowed in the ICLR format 
@misc{PyImage_Triangle,
howpublished = {\url{https://pyimagesearch.com/2015/01/19/find-distance-camera-objectmarker-using-python-opencv/}},
author = {Rosebrock, Adrian},
institution = {pyimagesearch},
title = {Find distance from camera to object/marker using Python and OpenCV},
note = {Accessed: 2023-06-15},
year = {2015}
}

% ResNet:
@article{He2015,
	author = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
	title = {Deep Residual Learning for Image Recognition},
	journal = {arXiv preprint arXiv:1512.03385},
	year = {2015}
}

% Alexnet:
@incollection{NIPS2012_4824,
  added-at = {2016-11-14T12:05:24.000+0100},
  author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
  biburl = {https://www.bibsonomy.org/bibtex/2886c491fe45049fee3c9660df30bb5c4/albinzehe},
  booktitle = {Advances in Neural Information Processing Systems 25},
  editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
  interhash = {74bbb5dea5afb1b088bd10e317f1f0d2},
  intrahash = {886c491fe45049fee3c9660df30bb5c4},
  keywords = {cnn deeplearning ma-zehe neuralnet},
  pages = {1097--1105},
  publisher = {Curran Associates, Inc.},
  timestamp = {2016-11-14T12:05:24.000+0100},
  title = {ImageNet Classification with Deep Convolutional Neural Networks},
  url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
  year = 2012
}

% U-Net:
@InProceedings{RFB15a,
  author       = "O. Ronneberger and P.Fischer and T. Brox",
  title        = "U-Net: Convolutional Networks for Biomedical Image Segmentation",
  booktitle    = "Medical Image Computing and Computer-Assisted Intervention (MICCAI)",
  series       = "LNCS",
  volume       = "9351",
  pages        = "234--241",
  year         = "2015",
  publisher    = "Springer",
  note         = "(available on arXiv:1505.04597 [cs.CV])",
  url          = "http://lmb.informatik.uni-freiburg.de/Publications/2015/RFB15a"
}

% DenseNet 2017:
@inproceedings{huang2017densely,
  title={Densely Connected Convolutional Networks},
  author={Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q },
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017}
}

%Dataset
@inproceedings{Silberman:ECCV12,
  author    = {Nathan Silberman, Derek Hoiem, Pushmeet Kohli and Rob Fergus},
  title     = {Indoor Segmentation and Support Inference from RGBD Images},
  booktitle = {ECCV},
  year      = {2012}
}

% Ito2019
@InProceedings{10.1007/978-3-030-11009-3_19,
author="Ito, Seiya
and Kaneko, Naoshi
and Shinohara, Yuma
and Sumi, Kazuhiko",
editor="Leal-Taix{\'e}, Laura
and Roth, Stefan",
title="Deep Modular Network Architecture for Depth Estimation from Single Indoor Images",
booktitle="Computer Vision -- ECCV 2018 Workshops",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="324--336",
abstract="We propose a novel deep modular network architecture for indoor scene depth estimation from single RGB images. The proposed architecture consists of a main depth estimation network and two auxiliary semantic segmentation networks. Our insight is that semantic and geometrical structures in a scene are strongly correlated, thus we utilize global (i.e. room layout) and mid-level (i.e. objects in a room) semantic structures to enhance depth estimation. The first auxiliary network, or layout network, is responsible for room layout estimation to infer the positions of walls, floor, and ceiling of a room. The second auxiliary network, or object network, estimates per-pixel class labels of the objects in a scene, such as furniture, to give mid-level semantic cues. Estimated semantic structures are effectively fed into the depth estimation network using newly proposed discriminator networks, which discern the reliability of the estimated structures. The evaluation result shows that our architecture achieves significant performance improvements over previous approaches on the standard NYU Depth v2 indoor scene dataset.",
isbn="978-3-030-11009-3"
}

% GAN
@article{Gan2014,
  title={Generative adversarial networks},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Communications of the ACM},
  volume={63},
  number={11},
  pages={139--144},
  year={2020},
  publisher={ACM New York, NY, USA}
}

% Monocular Depth Estimation Using Deep Learning: A Review
@Article{Masoumian,
AUTHOR = {Masoumian, Armin and Rashwan, Hatem A. and Cristiano, Juli√°n and Asif, M. Salman and Puig, Domenec},
TITLE = {Monocular Depth Estimation Using Deep Learning: A Review},
JOURNAL = {Sensors},
VOLUME = {22},
YEAR = {2022},
NUMBER = {14},
ARTICLE-NUMBER = {5353},
URL = {https://www.mdpi.com/1424-8220/22/14/5353},
PubMedID = {35891033},
ISSN = {1424-8220},
ABSTRACT = {In current decades, significant advancements in robotics engineering and autonomous vehicles have improved the requirement for precise depth measurements. Depth estimation (DE) is a traditional task in computer vision that can be appropriately predicted by applying numerous procedures. This task is vital in disparate applications such as augmented reality and target tracking. Conventional monocular DE (MDE) procedures are based on depth cues for depth prediction. Various deep learning techniques have demonstrated their potential applications in managing and supporting the traditional ill-posed problem. The principal purpose of this paper is to represent a state-of-the-art review of the current developments in MDE based on deep learning techniques. For this goal, this paper tries to highlight the critical points of the state-of-the-art works on MDE from disparate aspects. These aspects include input data shapes and training manners such as supervised, semi-supervised, and unsupervised learning approaches in combination with applying different datasets and evaluation indicators. At last, limitations regarding the accuracy of the DL-based MDE models, computational time requirements, real-time inference, transferability, input images shape and domain adaptation, and generalization are discussed to open new directions for future research.},
DOI = {10.3390/s22145353}
}


% Learning Depth from Single Monocular Images Using Deep Convolutional Neural Fields
@article{Liu_2016,
	doi = {10.1109/tpami.2015.2505283},
	url = {https://doi.org/10.1109\%2Ftpami.2015.2505283},
	year = 2016,
	month = {oct},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {38},
	number = {10},
	pages = {2024--2039},
	author = {Fayao Liu and Chunhua Shen and Guosheng Lin and Ian Reid},
	title = {Learning Depth from Single Monocular Images Using Deep Convolutional Neural Fields},
	journal = {{IEEE} Transactions on Pattern Analysis and Machine Intelligence}
}

% Tadepalli
@article{Tadepalli,
    doi = {10.18280/ts.380524},
    url = {https://doi.org/10.18280/ts.380524},
    year = 2021,
    author = {Yasasvy Tadepalli and Meenakshi Kollati and Swaraja Kuraparthi and Padmavathi Kora },
    title = {EfficientNet-B0 based monocular dense-depth map estimation},
    journal = {Traitement du Signal},
    volume = {38},
    number = {5},
    pages = {1485--1493}
}


% MobileNet
@misc{MobileNet2017,
      title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications}, 
      author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
      year={2017},
      eprint={1704.04861},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

% EfficientNet
@misc{tan2020efficientnet,
      title={EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks}, 
      author={Mingxing Tan and Quoc V. Le},
      year={2020},
      eprint={1905.11946},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

% DEPTH PERCEPTION WITH KNOW FOCAL LENGTH
@article{FocalDL,
	doi = {10.1109/tip.2018.2832296},
	url = {https://doi.org/10.1109\%2Ftip.2018.2832296},
	year = 2018,
	month = {sep},
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	volume = {27},
	number = {9},
	pages = {4676--4689},
	author = {Lei He and Guanghui Wang and Zhanyi Hu},
	title = {Learning Depth From Single Images With Deep Neural Network Embedding Focal Length},
	journal = {{IEEE} Transactions on Image Processing}
}

% VGG
@misc{VGG,
      title={Very Deep Convolutional Networks for Large-Scale Image Recognition}, 
      author={Karen Simonyan and Andrew Zisserman},
      year={2015},
      eprint={1409.1556},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}